[![Format](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/format.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/format.yml)
[![Lint](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/lint.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/lint.yml)
[![Install](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/install.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/install.yml)
[![Test](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/test.yml/badge.svg)](https://github.com/nogibjj/IDS706_DataEngineering_BarbaraFlores_Miniproject11/actions/workflows/test.yml)



IDS706_DataEngineering_BarbaraFlores_Miniproject11
# ðŸ“‚ Data Pipeline with Databricks

The primary purpose of this project is to design and develop an efficient data pipeline using Databricks. This pipeline should integrate data sources and destinations, emphasizing the designer's ability to perform extraction, transformation, and loading (ETL) tasks effectively. The focus is on ensuring the efficiency and scalability of the pipeline, along with the proper configuration of data sources and destinations.
